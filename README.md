# ğŸ¤– AI Data Analyst Agent (GPT-4.1 + LangChain + ReAct + FAISS)

An **AI-powered agent** for data analysis and visualization.  
Built with **FastAPI** and **Streamlit**, integrating **GPT-4.1 via LangChain**, automated **EDA**, and interactive **visualizations**.  

Upload your **CSV/Excel** files, generate **insights**, and ask questions in **natural language**.

---

## âœ¨ Features

- ğŸ§  Ask dataset questions via GPT-4.1 + LangChain  
- ğŸ“Š Automated EDA (profiling, correlations, distributions, time series)  
- ğŸ“ˆ Interactive visualizations (bar, scatter, line, heatmaps)  
- ğŸ“‚ Secure file upload and data cleaning  
- ğŸ Safe Python REPL for DataFrame manipulation  
- âš™ï¸ Robustness with multi-threading and retries on LLM calls  

---

## ğŸ§± Tech Stack

| Layer        | Tool / Library                             |
|--------------|---------------------------------------------|
| LLM Engine   | GPT-4.1 via [LangChain](https://www.langchain.com) |
| Web UI       | [Streamlit](https://streamlit.io)           |
| Backend API  | [FastAPI](https://fastapi.tiangolo.com)     |
| Data Analysis| `pandas`, `ydata-profiling`, `sweetviz`, `autoviz` |
| Visualization| `plotly`, `matplotlib`, `seaborn`, `lux`    |
| Memory     | FAISS (chat history)                       |

---

## ğŸ“‚ Project Structure

```
AI-Data-Analyst-Agent/
â”‚â”€â”€ backend/          # FastAPI backend (data processing, APIs, LLM integration)
â”‚â”€â”€ frontend/         # Streamlit frontend (UI, charts, dashboards)
â”‚â”€â”€ tests/            # Unit tests (pytest)
â”‚â”€â”€ data/             # Sample datasets + cleaned data
â”‚â”€â”€ requirements.txt  # Dependencies
â”‚â”€â”€ docker-compose.yml
â”‚â”€â”€ README.md
â”‚â”€â”€ .env      # Example environment variables
```
## ğŸ–¼ï¸ Interface Preview

### ğŸ  DataSense UI
<p align="center">
  <img src="agent.png" width="700" alt="DataSense" />
  
</p>
---

## ğŸš€ Installation

1. Clone the repository:
```bash
git clone https://github.com/your-username/AI-Data-Analyst-Agent.git
cd AI-Data-Analyst-Agent
```

2. Create a virtual environment:
```bash
python -m venv .venv
# Linux / Mac
source .venv/bin/activate
# Windows
.venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ Configuration

Create a `.env` file at the project root:

```env
# Token GitHub (NEVER COMMIT REAL TOKEN)
GITHUB_TOKEN=your_github_token_here

# LLM Model
MODEL_NAME=gpt-4.1

# GitHub Inference Endpoint
GITHUB_ENDPOINT=https://models.github.ai/inference

# Data paths
DATA_DIR=data
CLEAN_DIR=data/cleaned
CHAT_DB=data/chat_history.db
```

---

## ğŸƒ Run the Project

Start the **backend (FastAPI):**
```bash
uvicorn backend.main:app --reload
```

Start the **frontend (Streamlit):**
```bash
streamlit run frontend/main.py
```

---

## âœ… Tests

Run unit tests:
```bash
pytest tests/ -v
```

---

## ğŸ³ Docker Deployment (Optional)

Build and launch containers:
```bash
docker-compose build
docker-compose up
```

Stop services:
```bash
docker-compose down
```

Check logs:
```bash
docker-compose logs -f
```

âš  From the frontend container, use `http://backend:8000` to reach the backend.

---

## ğŸ§  Usage Examples

- "Summarize this dataset in 5 key insights"  
- "Show correlations between numerical variables"  
- "Plot the distribution of customer ages"  
- "Detect anomalies in sales time series"  

---

## ğŸ”§ Best Practices Applied

- âœ… Clear project structure (`backend/`, `frontend/`, `tests/`)  
- âœ… Error handling and logging  
- âœ… Unit testing with pytest  
- âœ… Reproducible documentation  

---

## ğŸ‘©â€ğŸ’» Author

**[Oumaima Toufali](https://www.linkedin.com/in/oumaima-toufali)**  

---
